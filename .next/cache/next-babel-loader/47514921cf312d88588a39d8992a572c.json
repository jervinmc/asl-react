{"ast":null,"code":"import React from \"react\";\nvar __jsx = React.createElement;\nimport { useEffect, useRef, useState } from 'react';\nimport service from '../services/service';\nimport { FontAwesomeIcon } from '@fortawesome/react-fontawesome';\nimport { faHandPaper } from '@fortawesome/free-solid-svg-icons'; // We'll limit the processing size to 200px.\n\nconst maxVideoSize = 224;\nconst LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_NOTHING', '_SPACE'];\nconst THRESHOLD = 5;\nconst THRESHOLDS = {\n  S: 3,\n  E: 5,\n  A: 5,\n  N: 6,\n  R: 5\n};\n/**\n * What we're going to render is:\n *\n * 1. A video component so the user can see what's on the camera.\n *\n * 2. A button to generate an image of the video, load OpenCV and\n * process the image.\n *\n * 3. A canvas to allow us to capture the image of the video and\n * show it to the user.\n */\n\nexport default function Page() {\n  const videoElement = useRef(null);\n  const canvasEl = useRef(null);\n  const outputCanvasEl = useRef(null);\n  let {\n    0: letter,\n    1: setLetter\n  } = useState(null);\n  let {\n    0: loading,\n    1: setLoading\n  } = useState(true);\n  let {\n    0: fps,\n    1: setFps\n  } = useState(0);\n  let {\n    0: words,\n    1: setWords\n  } = useState('');\n  /**\n   * In the onClick event we'll capture a frame within\n   * the video to pass it to our service.\n   */\n\n  async function processImage() {\n    if (videoElement !== null && canvasEl !== null && typeof videoElement.current !== 'undefined' && videoElement.current !== null) {\n      let frames = 0;\n      let start = Date.now();\n      let prevLetter = '';\n      let count = 0;\n      let _words = '';\n\n      const processWord = () => {\n        let wordsSplit = _words.split(' ');\n\n        fetch(`/api/autocorrect?word=${wordsSplit[wordsSplit.length - 1]}`).then(res => res.json()).then(json => {\n          const correctedWord = json['correctedWord'];\n          speechSynthesis.speak(new SpeechSynthesisUtterance(correctedWord));\n          wordsSplit.pop();\n          _words = wordsSplit.join(' ') + ' ' + correctedWord.toUpperCase() + ' ';\n          setWords(wordsSplit.join(' ') + ' ' + correctedWord.toUpperCase() + ' ');\n        });\n      };\n\n      videoElement.current.addEventListener('ended', () => processWord());\n\n      while (true) {\n        const ctx = canvasEl.current.getContext('2d');\n        ctx.drawImage(videoElement.current, 0, 0, maxVideoSize, maxVideoSize);\n        const image = ctx.getImageData(0, 0, maxVideoSize, maxVideoSize); // Processing image\n\n        const processedImage = await service.imageProcessing(image); // Render the processed image to the canvas\n\n        const ctxOutput = outputCanvasEl.current.getContext('2d');\n        ctxOutput.putImageData(processedImage.data.payload, 0, 0);\n        const prediction = await service.predict(processedImage.data.payload);\n        const predictedLetter = prediction.data.payload;\n        const letterValue = LETTERS[predictedLetter];\n        setLetter(letterValue);\n\n        if (letterValue !== prevLetter) {\n          if (!THRESHOLDS[prevLetter] ? count > THRESHOLD : count > THRESHOLDS[prevLetter]) {\n            if (prevLetter === '_SPACE') processWord();else {\n              _words = _words + (prevLetter === '_NOTHING' ? '' : prevLetter);\n              setWords((state, props) => state + (prevLetter === '_NOTHING' ? '' : prevLetter));\n            }\n          }\n\n          count = 0;\n        } else {\n          count++;\n        }\n\n        prevLetter = letterValue;\n        frames++;\n\n        if (frames === 10) {\n          setFps(10 / ((Date.now() - start) / 1000));\n          frames = 0;\n          start = Date.now();\n        }\n      }\n    }\n  }\n  /**\n   * In the useEffect hook we'll load the video\n   * element to show what's on camera.\n   */\n\n\n  useEffect(() => {\n    async function initCamera() {\n      videoElement.current.width = maxVideoSize;\n      videoElement.current.height = maxVideoSize;\n\n      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: false,\n          video: {\n            facingMode: 'environment',\n            width: maxVideoSize,\n            height: maxVideoSize\n          }\n        });\n        videoElement.current.srcObject = stream;\n        return new Promise(resolve => {\n          videoElement.current.onloadedmetadata = () => {\n            resolve(videoElement.current);\n          };\n        });\n      }\n\n      const errorMessage = 'This browser does not support video capture, or this device does not have a camera';\n      alert(errorMessage);\n      return Promise.reject(errorMessage);\n    }\n\n    async function load() {\n      const videoLoaded = await initCamera();\n      await service.load();\n      videoLoaded.play();\n      setTimeout(processImage, 0);\n      setLoading(false);\n      return videoLoaded;\n    }\n\n    load();\n  }, []);\n  return __jsx(\"div\", {\n    style: {\n      marginTop: '2em'\n    }\n  }, __jsx(\"h1\", {\n    className: \"text-center text-heading\",\n    style: {\n      marginBottom: '0.5em'\n    }\n  }), loading && __jsx(\"div\", {\n    className: \"row justify-content-center\"\n  }, __jsx(\"div\", {\n    className: \"col text-center\"\n  }, __jsx(\"div\", {\n    className: \"spinner-border\",\n    style: {\n      width: '8em',\n      height: '8em',\n      marginBottom: '2em'\n    },\n    role: \"status\"\n  }))), __jsx(\"div\", {\n    style: {\n      display: loading ? 'none' : 'block'\n    }\n  }, __jsx(\"div\", {\n    className: \"row justify-content-center\"\n  }, __jsx(\"div\", {\n    className: \"col-xs-12 text-center\"\n  }, __jsx(\"video\", {\n    className: \"video\",\n    playsInline: true,\n    ref: videoElement\n  })), __jsx(\"canvas\", {\n    style: {\n      display: 'none'\n    },\n    ref: canvasEl,\n    width: maxVideoSize,\n    height: maxVideoSize\n  }), __jsx(\"canvas\", {\n    className: \"col-xs-12\",\n    style: {\n      display: 'none'\n    },\n    ref: outputCanvasEl,\n    width: maxVideoSize,\n    height: maxVideoSize\n  })), __jsx(\"div\", {\n    className: \"row justify-content-center text-center\",\n    style: {\n      marginTop: '2em'\n    }\n  }, __jsx(\"div\", {\n    className: \"col-xs-12\"\n  }, __jsx(\"h5\", {\n    className: \"text-letter\"\n  }, \"Predicted Letter:\"), __jsx(\"h4\", {\n    className: \"text-letter\",\n    style: {\n      borderRadius: 10,\n      border: '2px solid #FFFFFF',\n      padding: '0.5em'\n    }\n  }, letter))), __jsx(\"div\", {\n    className: \"row justify-content-center text-center\",\n    style: {\n      marginTop: '2em'\n    }\n  })));\n}","map":null,"metadata":{},"sourceType":"module"}