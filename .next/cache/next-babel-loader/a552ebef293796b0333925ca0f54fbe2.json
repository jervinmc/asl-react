{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"@babel/runtime/helpers/esm/asyncToGenerator\";\nimport React from \"react\";\nvar __jsx = React.createElement;\nimport { useEffect, useRef, useState } from 'react';\nimport service from '../services/service';\nimport { FontAwesomeIcon } from '@fortawesome/react-fontawesome';\nimport { faHandPaper } from '@fortawesome/free-solid-svg-icons'; // We'll limit the processing size to 200px.\n\nvar maxVideoSize = 224;\nvar LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_NOTHING', '_SPACE'];\nvar THRESHOLD = 5;\nvar THRESHOLDS = {\n  S: 3,\n  E: 5,\n  A: 5,\n  N: 6,\n  R: 5\n};\n/**\n * What we're going to render is:\n *\n * 1. A video component so the user can see what's on the camera.\n *\n * 2. A button to generate an image of the video, load OpenCV and\n * process the image.\n *\n * 3. A canvas to allow us to capture the image of the video and\n * show it to the user.\n */\n\nexport default function Page() {\n  var videoElement = useRef(null);\n  var canvasEl = useRef(null);\n  var outputCanvasEl = useRef(null);\n\n  var _useState = useState(null),\n      letter = _useState[0],\n      setLetter = _useState[1];\n\n  var _useState2 = useState(true),\n      loading = _useState2[0],\n      setLoading = _useState2[1];\n\n  var _useState3 = useState(0),\n      fps = _useState3[0],\n      setFps = _useState3[1];\n\n  var _useState4 = useState(''),\n      words = _useState4[0],\n      setWords = _useState4[1];\n  /**\n   * In the onClick event we'll capture a frame within\n   * the video to pass it to our service.\n   */\n\n\n  function processImage() {\n    return _processImage.apply(this, arguments);\n  }\n  /**\n   * In the useEffect hook we'll load the video\n   * element to show what's on camera.\n   */\n\n\n  function _processImage() {\n    _processImage = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4() {\n      return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n        while (1) {\n          switch (_context4.prev = _context4.next) {\n            case 0:\n              if (!(videoElement !== null && canvasEl !== null && typeof videoElement.current !== 'undefined' && videoElement.current !== null)) {\n                _context4.next = 2;\n                break;\n              }\n\n              return _context4.delegateYield( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n                var frames, start, prevLetter, count, _words, processWord, ctx, image, processedImage, ctxOutput, prediction, predictedLetter, letterValue;\n\n                return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n                  while (1) {\n                    switch (_context3.prev = _context3.next) {\n                      case 0:\n                        frames = 0;\n                        start = Date.now();\n                        prevLetter = '';\n                        count = 0;\n                        _words = '';\n\n                        processWord = function processWord() {\n                          var wordsSplit = _words.split(' ');\n\n                          fetch(\"/api/autocorrect?word=\".concat(wordsSplit[wordsSplit.length - 1])).then(function (res) {\n                            return res.json();\n                          }).then(function (json) {\n                            var correctedWord = json['correctedWord'];\n                            speechSynthesis.speak(new SpeechSynthesisUtterance(correctedWord));\n                            wordsSplit.pop();\n                            _words = wordsSplit.join(' ') + ' ' + correctedWord.toUpperCase() + ' ';\n                            setWords(wordsSplit.join(' ') + ' ' + correctedWord.toUpperCase() + ' ');\n                          });\n                        };\n\n                        videoElement.current.addEventListener('ended', function () {\n                          return processWord();\n                        });\n\n                      case 7:\n                        if (!true) {\n                          _context3.next = 28;\n                          break;\n                        }\n\n                        ctx = canvasEl.current.getContext('2d');\n                        ctx.drawImage(videoElement.current, 0, 0, maxVideoSize, maxVideoSize);\n                        image = ctx.getImageData(0, 0, maxVideoSize, maxVideoSize); // Processing image\n\n                        _context3.next = 13;\n                        return service.imageProcessing(image);\n\n                      case 13:\n                        processedImage = _context3.sent;\n                        // Render the processed image to the canvas\n                        ctxOutput = outputCanvasEl.current.getContext('2d');\n                        ctxOutput.putImageData(processedImage.data.payload, 0, 0);\n                        _context3.next = 18;\n                        return service.predict(processedImage.data.payload);\n\n                      case 18:\n                        prediction = _context3.sent;\n                        predictedLetter = prediction.data.payload;\n                        letterValue = LETTERS[predictedLetter];\n                        setLetter(letterValue);\n\n                        if (letterValue !== prevLetter) {\n                          if (!THRESHOLDS[prevLetter] ? count > THRESHOLD : count > THRESHOLDS[prevLetter]) {\n                            if (prevLetter === '_SPACE') processWord();else {\n                              _words = _words + (prevLetter === '_NOTHING' ? '' : prevLetter);\n                              setWords(function (state, props) {\n                                return state + (prevLetter === '_NOTHING' ? '' : prevLetter);\n                              });\n                            }\n                          }\n\n                          count = 0;\n                        } else {\n                          count++;\n                        }\n\n                        prevLetter = letterValue;\n                        frames++;\n\n                        if (frames === 10) {\n                          setFps(10 / ((Date.now() - start) / 1000));\n                          frames = 0;\n                          start = Date.now();\n                        }\n\n                        _context3.next = 7;\n                        break;\n\n                      case 28:\n                      case \"end\":\n                        return _context3.stop();\n                    }\n                  }\n                }, _callee3);\n              })(), \"t0\", 2);\n\n            case 2:\n            case \"end\":\n              return _context4.stop();\n          }\n        }\n      }, _callee4);\n    }));\n    return _processImage.apply(this, arguments);\n  }\n\n  useEffect(function () {\n    function initCamera() {\n      return _initCamera.apply(this, arguments);\n    }\n\n    function _initCamera() {\n      _initCamera = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var stream, errorMessage;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                videoElement.current.width = maxVideoSize;\n                videoElement.current.height = maxVideoSize;\n\n                if (!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)) {\n                  _context.next = 8;\n                  break;\n                }\n\n                _context.next = 5;\n                return navigator.mediaDevices.getUserMedia({\n                  audio: false,\n                  video: {\n                    facingMode: 'environment',\n                    width: maxVideoSize,\n                    height: maxVideoSize\n                  }\n                });\n\n              case 5:\n                stream = _context.sent;\n                videoElement.current.srcObject = stream;\n                return _context.abrupt(\"return\", new Promise(function (resolve) {\n                  videoElement.current.onloadedmetadata = function () {\n                    resolve(videoElement.current);\n                  };\n                }));\n\n              case 8:\n                errorMessage = 'This browser does not support video capture, or this device does not have a camera';\n                alert(errorMessage);\n                return _context.abrupt(\"return\", Promise.reject(errorMessage));\n\n              case 11:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee);\n      }));\n      return _initCamera.apply(this, arguments);\n    }\n\n    function load() {\n      return _load.apply(this, arguments);\n    }\n\n    function _load() {\n      _load = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        var videoLoaded;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return initCamera();\n\n              case 2:\n                videoLoaded = _context2.sent;\n                _context2.next = 5;\n                return service.load();\n\n              case 5:\n                videoLoaded.play();\n                setTimeout(processImage, 0);\n                setLoading(false);\n                return _context2.abrupt(\"return\", videoLoaded);\n\n              case 9:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2);\n      }));\n      return _load.apply(this, arguments);\n    }\n\n    load();\n  }, []);\n  return __jsx(\"div\", {\n    style: {\n      marginTop: '2em'\n    }\n  }, __jsx(\"h1\", {\n    className: \"text-center text-heading\",\n    style: {\n      marginBottom: '0.5em'\n    }\n  }), loading && __jsx(\"div\", {\n    className: \"row justify-content-center\"\n  }, __jsx(\"div\", {\n    className: \"col text-center\"\n  }, __jsx(\"div\", {\n    className: \"spinner-border\",\n    style: {\n      width: '8em',\n      height: '8em',\n      marginBottom: '2em'\n    },\n    role: \"status\"\n  }))), __jsx(\"div\", {\n    style: {\n      display: loading ? 'none' : 'block'\n    }\n  }, __jsx(\"div\", {\n    className: \"row justify-content-center\"\n  }, __jsx(\"div\", {\n    className: \"col-xs-12 text-center\"\n  }, __jsx(\"video\", {\n    className: \"video\",\n    playsInline: true,\n    ref: videoElement\n  })), __jsx(\"canvas\", {\n    style: {\n      display: 'none'\n    },\n    ref: canvasEl,\n    width: maxVideoSize,\n    height: maxVideoSize\n  }), __jsx(\"canvas\", {\n    className: \"col-xs-12\",\n    style: {\n      display: 'none'\n    },\n    ref: outputCanvasEl,\n    width: maxVideoSize,\n    height: maxVideoSize\n  })), __jsx(\"div\", {\n    className: \"row justify-content-center text-center\",\n    style: {\n      marginTop: '2em'\n    }\n  }, __jsx(\"div\", {\n    className: \"col-xs-12\"\n  }, __jsx(\"h5\", {\n    className: \"text-letter\"\n  }, \"Predicted Letter:\"), __jsx(\"h4\", {\n    className: \"text-letter\",\n    style: {\n      borderRadius: 10,\n      border: '2px solid #FFFFFF',\n      padding: '0.5em'\n    }\n  }, letter))), __jsx(\"div\", {\n    className: \"row justify-content-center text-center\",\n    style: {\n      marginTop: '2em'\n    }\n  })));\n}","map":null,"metadata":{},"sourceType":"module"}